{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageIndex - HuggingFace Edition\n",
    "## Build Document Tree Structures with Free Local Models\n",
    "\n",
    "This notebook demonstrates how to use PageIndex with free HuggingFace models instead of OpenAI API.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ No OpenAI API key required\n",
    "- ‚úÖ Free and open-source models\n",
    "- ‚úÖ Run completely locally\n",
    "- ‚úÖ Good for document indexing and RAG systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pymupdf pyyaml transformers torch accelerate sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone Repository (or Upload Files)\n",
    "\n",
    "You can either clone from GitHub or upload the files manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Clone from GitHub (replace with your repo)\n",
    "# !git clone https://github.com/your-username/pageindex-hf.git\n",
    "# %cd pageindex-hf\n",
    "\n",
    "# Option 2: Use uploaded files\n",
    "import os\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"Files:\", os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Upload Your PDF\n",
    "\n",
    "Upload the PDF you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Upload PDF\n",
    "print(\"Please upload your PDF file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "pdf_path = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Configuration Files\n",
    "\n",
    "Create the necessary Python files if not already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If files were uploaded separately, skip this cell\n",
    "# Otherwise, create the files here\n",
    "\n",
    "# Check if files exist\n",
    "required_files = ['config.yaml', 'utils.py', 'page_index.py', 'run_pageindex.py']\n",
    "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ùå Missing files: {missing_files}\")\n",
    "    print(\"Please upload these files or clone the repository.\")\n",
    "else:\n",
    "    print(\"‚úÖ All required files present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run PageIndex\n",
    "\n",
    "Generate the tree structure for your PDF.\n",
    "\n",
    "**Note:** First run will download the model (~14GB for Mistral-7B). This may take 5-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Use command line (recommended)\n",
    "!python run_pageindex.py \\\n",
    "    --pdf_path {pdf_path} \\\n",
    "    --model \"mistralai/Mistral-7B-Instruct-v0.2\" \\\n",
    "    --device cuda \\\n",
    "    --max-pages-per-node 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View Results\n",
    "\n",
    "Load and display the generated tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the output JSON\n",
    "output_file = pdf_path.replace('.pdf', '_pageindex.json')\n",
    "\n",
    "with open(output_file, 'r') as f:\n",
    "    tree = json.load(f)\n",
    "\n",
    "# Display summary\n",
    "print(\"=\" * 60)\n",
    "print(\"üìÑ DOCUMENT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Description: {tree.get('document_description', 'N/A')}\")\n",
    "print(f\"Total Pages: {tree.get('total_pages', 'N/A')}\")\n",
    "print(f\"Total Nodes: {len(tree.get('nodes', []))}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üå≤ TREE STRUCTURE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display nodes\n",
    "for i, node in enumerate(tree.get('nodes', [])[:10]):  # Show first 10 nodes\n",
    "    print(f\"\\n{i+1}. {node.get('title', 'Untitled')}\")\n",
    "    print(f\"   Pages: {node.get('start_index', 'N/A')} - {node.get('end_index', 'N/A')}\")\n",
    "    if 'node_id' in node:\n",
    "        print(f\"   ID: {node['node_id']}\")\n",
    "    if 'summary' in node:\n",
    "        summary = node['summary'][:150] + \"...\" if len(node['summary']) > 150 else node['summary']\n",
    "        print(f\"   Summary: {summary}\")\n",
    "\n",
    "if len(tree.get('nodes', [])) > 10:\n",
    "    print(f\"\\n... and {len(tree['nodes']) - 10} more nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Download Results\n",
    "\n",
    "Download the generated JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the output\n",
    "output_file = pdf_path.replace('.pdf', '_pageindex.json')\n",
    "files.download(output_file)\n",
    "print(f\"‚úÖ Downloaded: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Use Programmatically\n",
    "\n",
    "You can also use PageIndex as a Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module\n",
    "from page_index import build_pageindex\n",
    "from utils import ConfigLoader\n",
    "\n",
    "# Load configuration\n",
    "config_loader = ConfigLoader()\n",
    "config = config_loader.load()\n",
    "\n",
    "# Build index\n",
    "tree = build_pageindex(\n",
    "    pdf_path=pdf_path,\n",
    "    config=config,\n",
    "    output_path=\"my_custom_output.json\"\n",
    ")\n",
    "\n",
    "print(f\"Generated tree with {len(tree['nodes'])} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Try Different Models\n",
    "\n",
    "Experiment with different HuggingFace models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a different model\n",
    "alternative_model = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "!python run_pageindex.py \\\n",
    "    --pdf_path {pdf_path} \\\n",
    "    --model {alternative_model} \\\n",
    "    --output \"output_zephyr.json\" \\\n",
    "    --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RAG Example\n",
    "\n",
    "Use the tree structure for basic retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_retrieve(query, tree, top_k=3):\n",
    "    \"\"\"Simple keyword-based retrieval from tree structure\"\"\"\n",
    "    query_words = set(query.lower().split())\n",
    "    \n",
    "    results = []\n",
    "    for node in tree['nodes']:\n",
    "        # Score based on keyword overlap\n",
    "        title_words = set(node.get('title', '').lower().split())\n",
    "        summary_words = set(node.get('summary', '').lower().split())\n",
    "        \n",
    "        overlap = len(query_words & (title_words | summary_words))\n",
    "        \n",
    "        if overlap > 0:\n",
    "            results.append({\n",
    "                'node': node,\n",
    "                'score': overlap\n",
    "            })\n",
    "    \n",
    "    # Sort by score and return top k\n",
    "    results.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return results[:top_k]\n",
    "\n",
    "# Example query\n",
    "query = \"financial results revenue\"\n",
    "results = simple_retrieve(query, tree, top_k=3)\n",
    "\n",
    "print(f\"\\nüîç Query: '{query}'\")\n",
    "print(\"=\" * 60)\n",
    "for i, result in enumerate(results, 1):\n",
    "    node = result['node']\n",
    "    print(f\"\\n{i}. {node.get('title', 'Untitled')} (Score: {result['score']})\")\n",
    "    print(f\"   Pages: {node.get('start_index')}-{node.get('end_index')}\")\n",
    "    if 'summary' in node:\n",
    "        print(f\"   Summary: {node['summary'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Next Steps\n",
    "\n",
    "1. **Integrate with your RAG system**: Use the tree structure for context retrieval\n",
    "2. **Try different models**: Experiment with various HuggingFace models\n",
    "3. **Customize configuration**: Adjust settings in `config.yaml`\n",
    "4. **Process multiple PDFs**: Loop through a directory of PDFs\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- [Original PageIndex](https://github.com/VectifyAI/PageIndex)\n",
    "- [HuggingFace Models](https://huggingface.co/models)\n",
    "- [PageIndex Documentation](https://docs.pageindex.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
